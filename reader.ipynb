{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import torch\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer,\n",
    "                          BitsAndBytesConfig, pipeline)\n",
    "from typing_extensions import List, TypedDict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = ('cuda' if torch.cuda.is_available() else\n",
    "          'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='all-mpnet-base-v2',\n",
    "                                   model_kwargs={'device': DEVICE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_documents(['test'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'tutorial'\n",
    "\n",
    "pc = Pinecone()\n",
    "# pc.delete_index(index_name)\n",
    "# pc.create_index(\n",
    "#     name=index_name,\n",
    "#     dimension=768,\n",
    "#     metric='cosine',\n",
    "#     spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "# )\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls = [\"https://www.apple.com/\"]\n",
    "# loader = WebBaseLoader(urls)\n",
    "# documents = loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# # Index chunks\n",
    "# _ = vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Define the user's question\n",
    "query = \"What new products are announced on Apple.com?\"\n",
    "\n",
    "# Retrieve relevant documents based on the query\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n--- Relevant Documents ---\")\n",
    "# for i, doc in enumerate(relevant_docs, 1):\n",
    "#     print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "#     if doc.metadata:\n",
    "#         print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs_text = [doc.page_content for doc in retrieved_docs]\n",
    "context = \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"HuggingFaceH4/zephyr-7b-beta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openai-community/gpt2-large'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=3840, nx=1280)\n",
       "          (c_proj): Conv1D(nf=1280, nx=1280)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=5120, nx=1280)\n",
       "          (c_proj): Conv1D(nf=1280, nx=5120)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='openai-community/gpt2-large', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x39a133c20>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"openai-community/gpt2-large\"\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model_name, device=DEVICE)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is 4+4? Answer: 4+4 means 'one plus four, or four equals four.' And this simple question is actually extremely important. Without a clear definition of '4+4,' we cannot understand how it is not four,\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"What is 4+4? Answer:\")[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,  1824,   349, 28705, 28781, 28806, 28781, 28804, 26307, 28747]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_with_doc = tokenizer('What is 4+4? Answer:', return_tensors=\"pt\")\n",
    "inputs_with_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = model.generate(**inputs_with_doc, pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> What is 4+4? Answer:G<s>��<s> roi is 4+4<s>��<s> roi is 4+'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tokenizer.batch_decode(answers)[0].split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.tokenizer.chat_template = chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
      "<|user|>\n",
      "Context:\n",
      "{context}\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: {question}</s>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using the information contained in the context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = re.sub(r'\\n{2,}', '', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
      "<|user|>\n",
      "Context:\n",
      "Document 0:::\n",
      "AppleAppleAppleStoreMaciPadiPhoneWatch\n",
      "VisionAirPodsTV & HomeEntertainmentAccessoriesSupport0+ MacBook Air\n",
      "Sky blue color.Sky high performance with M4.Learn more\n",
      "BuyBuilt for Apple Intelligence. iPad Air\n",
      "Now supercharged by the M3 chip.Learn more\n",
      "BuyBuilt for Apple Intelligence. Mac Studio\n",
      "M4 Max and M3 Ultra. Choose your superpower.Learn more\n",
      "BuyBuilt for Apple Intelligence. iPad\n",
      "Now with the speed of the A16 chip and double the starting storage.Learn more\n",
      "Buy iPhone\n",
      "Meet the iPhone 16 family.Learn more\n",
      "Shop iPhoneBuilt for Apple Intelligence. Apple Trade In\n",
      "Get $170–$630 in credit when you trade in iPhone 12 or higher.1Get your estimate Apple Watch Series 10\n",
      "Thinstant classic.Learn more\n",
      "Buy AirPods Pro 2\n",
      "Now with a Hearing Aid feature.2Learn more\n",
      "BuyDocument 1:::\n",
      "For BusinessApple and Business\n",
      "Shop for BusinessFor EducationFor EducationApple and Education\n",
      "Shop for K-12\n",
      "Shop for CollegeFor HealthcareFor HealthcareApple in Healthcare\n",
      "Mac in Healthcare\n",
      "Health on Apple Watch\n",
      "Health Records on iPhone and iPadFor GovernmentFor GovernmentShop for Government\n",
      "Shop for Veterans and MilitaryApple ValuesApple ValuesAccessibility\n",
      "Education\n",
      "Environment\n",
      "Inclusion and Diversity\n",
      "Privacy\n",
      "Racial Equity and Justice\n",
      "Supply ChainAbout AppleAbout AppleNewsroom\n",
      "Apple Leadership\n",
      "Career Opportunities\n",
      "Investors\n",
      "Ethics & Compliance\n",
      "Events\n",
      "Contact Apple\t\t\tMore ways to shop: Find an Apple Store or other retailer near you. Or call 1-800-MY-APPLE.United StatesCopyright ©\n",
      "\t\t\t\t\n",
      "\t\t\t\t2025\n",
      "\t\t\t\t Apple Inc. All rights reserved.\n",
      "\t\t\tPrivacy PolicyTerms of UseSales and RefundsLegalSite MapDocument 2:::\n",
      "A subscription is required for Apple Arcade, Apple Fitness+, Apple Music, and Apple TV+.Features are subject to change. Some features, applications, and services may not be available in all regions or all languages.Shop and LearnShop and LearnStore\n",
      "Mac\n",
      "iPad\n",
      "iPhone\n",
      "Watch\n",
      "Vision\n",
      "AirPods\n",
      "TV & Home\n",
      "AirTag\n",
      "Accessories\n",
      "Gift CardsApple WalletApple WalletWallet\n",
      "Apple Card\n",
      "Apple Pay\n",
      "Apple CashAccountAccountManage Your Apple Account\n",
      "Apple Store Account\n",
      "iCloud.comEntertainmentEntertainmentApple One\n",
      "Apple TV+\n",
      "Apple Music\n",
      "Apple Arcade\n",
      "Apple Fitness+\n",
      "Apple News+\n",
      "Apple Podcasts\n",
      "Apple Books\n",
      "App StoreApple StoreApple StoreFind a Store\n",
      "Genius Bar\n",
      "Today at Apple\n",
      "Group Reservations\n",
      "Apple Camp\n",
      "Apple Store App\n",
      "Certified Refurbished\n",
      "Apple Trade In\n",
      "Financing\n",
      "Carrier Deals at Apple\n",
      "Order Status\n",
      "Shopping HelpFor BusinessFor BusinessApple and Business\n",
      "Shop for BusinessFor EducationFor Education\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: What new products are announced on Apple.com?</s>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = RAG_PROMPT_TEMPLATE.format(question=query, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nUsing the information contained in the context,\\ngive a comprehensive answer to the question.\\nRespond only to the question asked, response should be concise and relevant to the question.\\nProvide the number of the source document when relevant.\\nIf the answer cannot be deduced from the context, do not give an answer.</s>\\n<|user|>\\nContext:\\nDocument 0:::\\nAppleAppleAppleStoreMaciPadiPhoneWatch\\nVisionAirPodsTV & HomeEntertainmentAccessoriesSupport0+\\xa0MacBook Air\\nSky blue color.Sky high performance with M4.Learn more\\nBuyBuilt for Apple Intelligence.\\xa0iPad Air\\nNow supercharged by the M3 chip.Learn more\\nBuyBuilt for Apple Intelligence.\\xa0Mac Studio\\nM4\\xa0Max and M3\\xa0Ultra. Choose your superpower.Learn more\\nBuyBuilt for Apple Intelligence.\\xa0iPad\\nNow with the speed of the A16 chip and double the starting storage.Learn more\\nBuy\\xa0iPhone\\nMeet the iPhone 16 family.Learn more\\nShop iPhoneBuilt for Apple Intelligence.\\xa0Apple Trade In\\nGet $170–$630 in credit when you trade in iPhone\\xa012 or higher.1Get your estimate\\xa0Apple Watch Series 10\\nThinstant classic.Learn more\\nBuy\\xa0AirPods\\xa0Pro\\xa02\\nNow with a Hearing\\xa0Aid feature.2Learn more\\nBuyDocument 1:::\\nFor BusinessApple and Business\\nShop for BusinessFor EducationFor EducationApple and Education\\nShop for K-12\\nShop for CollegeFor HealthcareFor HealthcareApple in Healthcare\\nMac in Healthcare\\nHealth on Apple\\xa0Watch\\nHealth Records on iPhone and iPadFor GovernmentFor GovernmentShop for Government\\nShop for Veterans and MilitaryApple ValuesApple ValuesAccessibility\\nEducation\\nEnvironment\\nInclusion and Diversity\\nPrivacy\\nRacial Equity and Justice\\nSupply ChainAbout AppleAbout AppleNewsroom\\nApple Leadership\\nCareer Opportunities\\nInvestors\\nEthics & Compliance\\nEvents\\nContact Apple\\t\\t\\tMore ways to shop: Find an Apple Store or other retailer near you. Or call 1-800-MY-APPLE.United StatesCopyright ©\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t2025\\n\\t\\t\\t\\t Apple Inc. All rights reserved.\\n\\t\\t\\tPrivacy PolicyTerms of UseSales and RefundsLegalSite MapDocument 2:::\\nA subscription is required for Apple\\xa0Arcade, Apple\\xa0Fitness+, Apple\\xa0Music, and Apple\\xa0TV+.Features are subject to change. Some features, applications, and services may not be available in all regions or all languages.Shop and LearnShop and LearnStore\\nMac\\niPad\\niPhone\\nWatch\\nVision\\nAirPods\\nTV & Home\\nAirTag\\nAccessories\\nGift CardsApple WalletApple WalletWallet\\nApple\\xa0Card\\nApple\\xa0Pay\\nApple\\xa0CashAccountAccountManage Your Apple Account\\nApple Store Account\\niCloud.comEntertainmentEntertainmentApple\\xa0One\\nApple\\xa0TV+\\nApple\\xa0Music\\nApple\\xa0Arcade\\nApple\\xa0Fitness+\\nApple\\xa0News+\\nApple Podcasts\\nApple\\xa0Books\\nApp\\xa0StoreApple StoreApple StoreFind a Store\\nGenius Bar\\nToday at Apple\\nGroup Reservations\\nApple Camp\\nApple Store App\\nCertified Refurbished\\nApple\\xa0Trade\\xa0In\\nFinancing\\nCarrier Deals at Apple\\nOrder Status\\nShopping HelpFor BusinessFor BusinessApple and Business\\nShop for BusinessFor EducationFor Education\\n---\\nNow here is the question you need to answer.\\n\\nQuestion: What new products are announced on Apple.com?</s>\\n<|assistant|>\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   27,    91, 10057,    91,    29,   198, 12814,   262,  1321,  7763,\n",
       "           287,   262,  4732,    11,   198, 26535,   257,  9815,  3280,   284,\n",
       "           262,  1808,    13,   198, 19309,   623,   691,   284,   262,  1808,\n",
       "          1965,    11,  2882,   815,   307, 35327,   290,  5981,   284,   262,\n",
       "          1808,    13,   198, 15946,   485,   262,  1271,   286,   262,  2723,\n",
       "          3188,   618,  5981,    13,   198,  1532,   262,  3280,  2314,   307,\n",
       "          4648, 19513,   422,   262,  4732,    11,   466,   407,  1577,   281,\n",
       "          3280, 25970,    82,    29,   198,    27,    91,  7220,    91,    29,\n",
       "           198, 21947,    25,   198, 24941,   657,  3712,    25,   198, 16108,\n",
       "         16108, 16108, 22658, 14155,    72,    47,  9189,  6132, 10723,   198,\n",
       "         44206, 16170,    47, 12978,  6849,  1222,  5995, 17469, 10738, 15457,\n",
       "          1749, 15514,    15,    10,  1849, 14155, 10482,  3701,   198, 22308,\n",
       "          4171,  3124,    13, 22308,  1029,  2854,   351,   337,    19,    13,\n",
       "         20238,   517,   198, 14518, 39582,   329,  4196,  9345,    13,  1849,\n",
       "            72, 26114,  3701,   198,  3844,  2208, 17200,   416,   262,   337,\n",
       "            18, 11594,    13, 20238,   517,   198, 14518, 39582,   329,  4196,\n",
       "          9345,    13,  1849, 14155, 11733,   198,    44,    19,  1849, 11518,\n",
       "           290,   337,    18,  1849, 36122,    13, 17489,   534, 47481,    13,\n",
       "         20238,   517,   198, 14518, 39582,   329,  4196,  9345,    13,  1849,\n",
       "            72, 26114,   198,  3844,   351,   262,  2866,   286,   262,   317,\n",
       "          1433, 11594,   290,  4274,   262,  3599,  6143,    13, 20238,   517,\n",
       "           198, 14518,  1849, 37032,   198, 29318,   262,  7133,  1467,  1641,\n",
       "            13, 20238,   517,   198, 29917,  7133, 39582,   329,  4196,  9345,\n",
       "            13,  1849, 16108,  9601,   554,   198,  3855,   720, 17279,  1906,\n",
       "             3, 30005,   287,  3884,   618,   345,  3292,   287,  7133,  1849,\n",
       "          1065,   393,  2440,    13,    16,  3855,   534,  8636,  1849, 16108,\n",
       "          6305,  7171,   838,   198,   817,  8625,   415,  6833,    13, 20238,\n",
       "           517,   198, 14518,  1849, 16170,    47, 12978,  1849,  2964,  1849,\n",
       "            17,   198,  3844,   351,   257, 34663,  1849, 44245,  3895,    13,\n",
       "            17, 20238,   517,   198, 14518, 24941,   352,  3712,    25,   198,\n",
       "          1890,  7320, 16108,   290,  7320,   198, 29917,   329,  7320,  1890,\n",
       "          7868,  1890,  7868, 16108,   290,  7868,   198, 29917,   329,   509,\n",
       "            12,  1065,   198, 29917,   329,  5535,  1890, 30289,  1890, 30289,\n",
       "         16108,   287, 30289,   198, 14155,   287, 30289,   198, 18081,   319,\n",
       "          4196,  1849, 10723,   198, 18081, 13407,   319,  7133,   290, 13133,\n",
       "          1890,  5070,  1890,  5070, 29917,   329,  5070,   198, 29917,   329,\n",
       "         18950,   290, 12842, 16108, 27068, 16108, 27068, 15457,  2247,   198,\n",
       "         41183,   198, 31441,   198,   818,  4717,   290, 36188,   198, 48948,\n",
       "           198,    49, 18150, 35659,   290,  4796,   198, 15979,   306, 21853,\n",
       "          8585,  4196,  8585,  4196,  9980,  3823,   198, 16108, 26935,   198,\n",
       "         17784,   263, 24922,   871,   198, 19070,   669,   198, 40226,   873,\n",
       "          1222, 40536,   198, 37103,   198, 17829,  4196,   197,   197,   197,\n",
       "          5167,  2842,   284,  6128,    25,  9938,   281,  4196,  9363,   393,\n",
       "           584, 21538,  1474,   345,    13,  1471,   869,   352,    12,  7410,\n",
       "            12, 26708,    12,  2969, 16437,    13, 17013,  1829, 15269, 10673,\n",
       "           198,   197,   197,   197,   197,   198,   197,   197,   197,   197,\n",
       "          1238,  1495,   198,   197,   197,   197,   197,  4196,  3457,    13,\n",
       "          1439,  2489, 10395,    13,   198,   197,   197,   197, 48948,  7820,\n",
       "         15156,   907,   286,  5765, 44490,   290,  6524,   917,    82, 38263,\n",
       "         29123,  9347, 24941,   362,  3712,    25,   198,    32, 14569,   318,\n",
       "          2672,   329,  4196,  1849, 43763,    11,  4196,  1849,    37,  3659,\n",
       "         28200,  4196,  1849, 22648,    11,   290,  4196,  1849,  6849, 27613,\n",
       "         23595,   389,  2426,   284,  1487,    13,  2773,  3033,    11,  5479,\n",
       "            11,   290,  2594,   743,   407,   307,  1695,   287,   477,  7652,\n",
       "           393,   477,  8950,    13, 29917,   290, 14365, 29917,   290, 14365,\n",
       "         22658,   198, 14155,   198,    72, 26114,   198, 37032,   198, 10723,\n",
       "           198, 44206,   198, 16170,    47, 12978,   198,  6849,  1222,  5995,\n",
       "           198, 16170, 24835,   198, 15457,  1749,   198,    38,  2135, 15824,\n",
       "         16108, 37249, 16108, 37249, 47152,   198, 16108,  1849, 16962,   198,\n",
       "         16108,  1849, 19197,   198, 16108,  1849, 35361, 30116, 30116,  5124,\n",
       "           496,  3406,  4196, 10781,   198, 16108,  9363, 10781,   198,    72,\n",
       "         18839,    13,   785, 17469, 10738, 17469, 10738, 16108,  1849,  3198,\n",
       "           198, 16108,  1849,  6849,    10,   198, 16108,  1849, 22648,   198,\n",
       "         16108,  1849, 43763,   198, 16108,  1849,    37,  3659,    10,   198,\n",
       "         16108,  1849,  9980,    10,   198, 16108, 16036,    82,   198, 16108,\n",
       "          1849, 30650,   198,  4677,  1849, 22658, 16108,  9363, 16108,  9363,\n",
       "         16742,   257,  9363,   198, 13746,  3754,  2409,   198,  8888,   379,\n",
       "          4196,   198, 13247, 40425,   602,   198, 16108,  5425,   198, 16108,\n",
       "          9363,  2034,   198, 37608,  1431,  6524,  5945,  1348,   198, 16108,\n",
       "          1849, 35965,  1849,   818,   198, 18467,  5077,   198,  9914,  5277,\n",
       "         38299,   379,  4196,   198, 18743, 12678,   198,  2484, 33307, 10478,\n",
       "          1890,  7320,  1890,  7320, 16108,   290,  7320,   198, 29917,   329,\n",
       "          7320,  1890,  7868,  1890,  7868,   198,  6329,   198,  3844,   994,\n",
       "           318,   262,  1808,   345,   761,   284,  3280,    13,   198,   198,\n",
       "         24361,    25,  1867,   649,  3186,   389,  3414,   319,  4196,    13,\n",
       "           785,    30,  3556,    82,    29,   198,    27,    91,   562, 10167,\n",
       "            91,    29,   198]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='mps:0')}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   27,    91, 10057,    91,    29,   198, 12814,   262,  1321,  7763,\n",
       "           287,   262,  4732,    11,   198, 26535,   257,  9815,  3280,   284,\n",
       "           262,  1808,    13,   198, 19309,   623,   691,   284,   262,  1808,\n",
       "          1965,    11,  2882,   815,   307, 35327,   290,  5981,   284,   262,\n",
       "          1808,    13,   198, 15946,   485,   262,  1271,   286,   262,  2723,\n",
       "          3188,   618,  5981,    13,   198,  1532,   262,  3280,  2314,   307,\n",
       "          4648, 19513,   422,   262,  4732,    11,   466,   407,  1577,   281,\n",
       "          3280, 25970,    82,    29,   198,    27,    91,  7220,    91,    29,\n",
       "           198, 21947,    25,   198, 24941,   657,  3712,    25,   198, 16108,\n",
       "         16108, 16108, 22658, 14155,    72,    47,  9189,  6132, 10723,   198,\n",
       "         44206, 16170,    47, 12978,  6849,  1222,  5995, 17469, 10738, 15457,\n",
       "          1749, 15514,    15,    10,  1849, 14155, 10482,  3701,   198, 22308,\n",
       "          4171,  3124,    13, 22308,  1029,  2854,   351,   337,    19,    13,\n",
       "         20238,   517,   198, 14518, 39582,   329,  4196,  9345,    13,  1849,\n",
       "            72, 26114,  3701,   198,  3844,  2208, 17200,   416,   262,   337,\n",
       "            18, 11594,    13, 20238,   517,   198, 14518, 39582,   329,  4196,\n",
       "          9345,    13,  1849, 14155, 11733,   198,    44,    19,  1849, 11518,\n",
       "           290,   337,    18,  1849, 36122,    13, 17489,   534, 47481,    13,\n",
       "         20238,   517,   198, 14518, 39582,   329,  4196,  9345,    13,  1849,\n",
       "            72, 26114,   198,  3844,   351,   262,  2866,   286,   262,   317,\n",
       "          1433, 11594,   290,  4274,   262,  3599,  6143,    13, 20238,   517,\n",
       "           198, 14518,  1849, 37032,   198, 29318,   262,  7133,  1467,  1641,\n",
       "            13, 20238,   517,   198, 29917,  7133, 39582,   329,  4196,  9345,\n",
       "            13,  1849, 16108,  9601,   554,   198,  3855,   720, 17279,  1906,\n",
       "             3, 30005,   287,  3884,   618,   345,  3292,   287,  7133,  1849,\n",
       "          1065,   393,  2440,    13,    16,  3855,   534,  8636,  1849, 16108,\n",
       "          6305,  7171,   838,   198,   817,  8625,   415,  6833,    13, 20238,\n",
       "           517,   198, 14518,  1849, 16170,    47, 12978,  1849,  2964,  1849,\n",
       "            17,   198,  3844,   351,   257, 34663,  1849, 44245,  3895,    13,\n",
       "            17, 20238,   517,   198, 14518, 24941,   352,  3712,    25,   198,\n",
       "          1890,  7320, 16108,   290,  7320,   198, 29917,   329,  7320,  1890,\n",
       "          7868,  1890,  7868, 16108,   290,  7868,   198, 29917,   329,   509,\n",
       "            12,  1065,   198, 29917,   329,  5535,  1890, 30289,  1890, 30289,\n",
       "         16108,   287, 30289,   198, 14155,   287, 30289,   198, 18081,   319,\n",
       "          4196,  1849, 10723,   198, 18081, 13407,   319,  7133,   290, 13133,\n",
       "          1890,  5070,  1890,  5070, 29917,   329,  5070,   198, 29917,   329,\n",
       "         18950,   290, 12842, 16108, 27068, 16108, 27068, 15457,  2247,   198,\n",
       "         41183,   198, 31441,   198,   818,  4717,   290, 36188,   198, 48948,\n",
       "           198,    49, 18150, 35659,   290,  4796,   198, 15979,   306, 21853,\n",
       "          8585,  4196,  8585,  4196,  9980,  3823,   198, 16108, 26935,   198,\n",
       "         17784,   263, 24922,   871,   198, 19070,   669,   198, 40226,   873,\n",
       "          1222, 40536,   198, 37103,   198, 17829,  4196,   197,   197,   197,\n",
       "          5167,  2842,   284,  6128,    25,  9938,   281,  4196,  9363,   393,\n",
       "           584, 21538,  1474,   345,    13,  1471,   869,   352,    12,  7410,\n",
       "            12, 26708,    12,  2969, 16437,    13, 17013,  1829, 15269, 10673,\n",
       "           198,   197,   197,   197,   197,   198,   197,   197,   197,   197,\n",
       "          1238,  1495,   198,   197,   197,   197,   197,  4196,  3457,    13,\n",
       "          1439,  2489, 10395,    13,   198,   197,   197,   197, 48948,  7820,\n",
       "         15156,   907,   286,  5765, 44490,   290,  6524,   917,    82, 38263,\n",
       "         29123,  9347, 24941,   362,  3712,    25,   198,    32, 14569,   318,\n",
       "          2672,   329,  4196,  1849, 43763,    11,  4196,  1849,    37,  3659,\n",
       "         28200,  4196,  1849, 22648,    11,   290,  4196,  1849,  6849, 27613,\n",
       "         23595,   389,  2426,   284,  1487,    13,  2773,  3033,    11,  5479,\n",
       "            11,   290,  2594,   743,   407,   307,  1695,   287,   477,  7652,\n",
       "           393,   477,  8950,    13, 29917,   290, 14365, 29917,   290, 14365,\n",
       "         22658,   198, 14155,   198,    72, 26114,   198, 37032,   198, 10723,\n",
       "           198, 44206,   198, 16170,    47, 12978,   198,  6849,  1222,  5995,\n",
       "           198, 16170, 24835,   198, 15457,  1749,   198,    38,  2135, 15824,\n",
       "         16108, 37249, 16108, 37249, 47152,   198, 16108,  1849, 16962,   198,\n",
       "         16108,  1849, 19197,   198, 16108,  1849, 35361, 30116, 30116,  5124,\n",
       "           496,  3406,  4196, 10781,   198, 16108,  9363, 10781,   198,    72,\n",
       "         18839,    13,   785, 17469, 10738, 17469, 10738, 16108,  1849,  3198,\n",
       "           198, 16108,  1849,  6849,    10,   198, 16108,  1849, 22648,   198,\n",
       "         16108,  1849, 43763,   198, 16108,  1849,    37,  3659,    10,   198,\n",
       "         16108,  1849,  9980,    10,   198, 16108, 16036,    82,   198, 16108,\n",
       "          1849, 30650,   198,  4677,  1849, 22658, 16108,  9363, 16108,  9363,\n",
       "         16742,   257,  9363,   198, 13746,  3754,  2409,   198,  8888,   379,\n",
       "          4196,   198, 13247, 40425,   602,   198, 16108,  5425,   198, 16108,\n",
       "          9363,  2034,   198, 37608,  1431,  6524,  5945,  1348,   198, 16108,\n",
       "          1849, 35965,  1849,   818,   198, 18467,  5077,   198,  9914,  5277,\n",
       "         38299,   379,  4196,   198, 18743, 12678,   198,  2484, 33307, 10478,\n",
       "          1890,  7320,  1890,  7320, 16108,   290,  7320,   198, 29917,   329,\n",
       "          7320,  1890,  7868,  1890,  7868,   198,  6329,   198,  3844,   994,\n",
       "           318,   262,  1808,   345,   761,   284,  3280,    13,   198,   198,\n",
       "         24361,    25,  1867,   649,  3186,   389,  3414,   319,  4196,    13,\n",
       "           785,    30,  3556,    82,    29,   198,    27,    91,   562, 10167,\n",
       "            91,    29,   198, 21947,    25,   198, 16108,    13,   785,   318,\n",
       "           262,  1363,   286,   262,   995,   338,   749,  2968,  2614,  9061,\n",
       "            11,  1390,   262]], device='mps:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = model.generate(**prompt_tokens, pad_token_id=tokenizer.eos_token_id)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
      "<|user|>\n",
      "Context:\n",
      "Document 0:::\n",
      "AppleAppleAppleStoreMaciPadiPhoneWatch\n",
      "VisionAirPodsTV & HomeEntertainmentAccessoriesSupport0+ MacBook Air\n",
      "Sky blue color.Sky high performance with M4.Learn more\n",
      "BuyBuilt for Apple Intelligence. iPad Air\n",
      "Now supercharged by the M3 chip.Learn more\n",
      "BuyBuilt for Apple Intelligence. Mac Studio\n",
      "M4 Max and M3 Ultra. Choose your superpower.Learn more\n",
      "BuyBuilt for Apple Intelligence. iPad\n",
      "Now with the speed of the A16 chip and double the starting storage.Learn more\n",
      "Buy iPhone\n",
      "Meet the iPhone 16 family.Learn more\n",
      "Shop iPhoneBuilt for Apple Intelligence. Apple Trade In\n",
      "Get $170–$630 in credit when you trade in iPhone 12 or higher.1Get your estimate Apple Watch Series 10\n",
      "Thinstant classic.Learn more\n",
      "Buy AirPods Pro 2\n",
      "Now with a Hearing Aid feature.2Learn more\n",
      "BuyDocument 1:::\n",
      "For BusinessApple and Business\n",
      "Shop for BusinessFor EducationFor EducationApple and Education\n",
      "Shop for K-12\n",
      "Shop for CollegeFor HealthcareFor HealthcareApple in Healthcare\n",
      "Mac in Healthcare\n",
      "Health on Apple Watch\n",
      "Health Records on iPhone and iPadFor GovernmentFor GovernmentShop for Government\n",
      "Shop for Veterans and MilitaryApple ValuesApple ValuesAccessibility\n",
      "Education\n",
      "Environment\n",
      "Inclusion and Diversity\n",
      "Privacy\n",
      "Racial Equity and Justice\n",
      "Supply ChainAbout AppleAbout AppleNewsroom\n",
      "Apple Leadership\n",
      "Career Opportunities\n",
      "Investors\n",
      "Ethics & Compliance\n",
      "Events\n",
      "Contact Apple\t\t\tMore ways to shop: Find an Apple Store or other retailer near you. Or call 1-800-MY-APPLE.United StatesCopyright ©\n",
      "\t\t\t\t\n",
      "\t\t\t\t2025\n",
      "\t\t\t\t Apple Inc. All rights reserved.\n",
      "\t\t\tPrivacy PolicyTerms of UseSales and RefundsLegalSite MapDocument 2:::\n",
      "A subscription is required for Apple Arcade, Apple Fitness+, Apple Music, and Apple TV+.Features are subject to change. Some features, applications, and services may not be available in all regions or all languages.Shop and LearnShop and LearnStore\n",
      "Mac\n",
      "iPad\n",
      "iPhone\n",
      "Watch\n",
      "Vision\n",
      "AirPods\n",
      "TV & Home\n",
      "AirTag\n",
      "Accessories\n",
      "Gift CardsApple WalletApple WalletWallet\n",
      "Apple Card\n",
      "Apple Pay\n",
      "Apple CashAccountAccountManage Your Apple Account\n",
      "Apple Store Account\n",
      "iCloud.comEntertainmentEntertainmentApple One\n",
      "Apple TV+\n",
      "Apple Music\n",
      "Apple Arcade\n",
      "Apple Fitness+\n",
      "Apple News+\n",
      "Apple Podcasts\n",
      "Apple Books\n",
      "App StoreApple StoreApple StoreFind a Store\n",
      "Genius Bar\n",
      "Today at Apple\n",
      "Group Reservations\n",
      "Apple Camp\n",
      "Apple Store App\n",
      "Certified Refurbished\n",
      "Apple Trade In\n",
      "Financing\n",
      "Carrier Deals at Apple\n",
      "Order Status\n",
      "Shopping HelpFor BusinessFor BusinessApple and Business\n",
      "Shop for BusinessFor EducationFor Education\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: What new products are announced on Apple.com?</s>\n",
      "<|assistant|>\n",
      "Context:\n",
      "Apple.com is the home of the world's most popular personal computers, including the\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(answer)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "llm = pipeline(\"text-generation\", model=model_name, device=DEVICE, max_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
      "<|user|>\n",
      "Context:\n",
      "Document 0:::\n",
      "AppleAppleAppleStoreMaciPadiPhoneWatch\n",
      "VisionAirPodsTV & HomeEntertainmentAccessoriesSupport0+ MacBook Air\n",
      "Sky blue color.Sky high performance with M4.Learn more\n",
      "BuyBuilt for Apple Intelligence. iPad Air\n",
      "Now supercharged by the M3 chip.Learn more\n",
      "BuyBuilt for Apple Intelligence. Mac Studio\n",
      "M4 Max and M3 Ultra. Choose your superpower.Learn more\n",
      "BuyBuilt for Apple Intelligence. iPad\n",
      "Now with the speed of the A16 chip and double the starting storage.Learn more\n",
      "Buy iPhone\n",
      "Meet the iPhone 16 family.Learn more\n",
      "Shop iPhoneBuilt for Apple Intelligence. Apple Trade In\n",
      "Get $170–$630 in credit when you trade in iPhone 12 or higher.1Get your estimate Apple Watch Series 10\n",
      "Thinstant classic.Learn more\n",
      "Buy AirPods Pro 2\n",
      "Now with a Hearing Aid feature.2Learn more\n",
      "BuyDocument 1:::\n",
      "For BusinessApple and Business\n",
      "Shop for BusinessFor EducationFor EducationApple and Education\n",
      "Shop for K-12\n",
      "Shop for CollegeFor HealthcareFor HealthcareApple in Healthcare\n",
      "Mac in Healthcare\n",
      "Health on Apple Watch\n",
      "Health Records on iPhone and iPadFor GovernmentFor GovernmentShop for Government\n",
      "Shop for Veterans and MilitaryApple ValuesApple ValuesAccessibility\n",
      "Education\n",
      "Environment\n",
      "Inclusion and Diversity\n",
      "Privacy\n",
      "Racial Equity and Justice\n",
      "Supply ChainAbout AppleAbout AppleNewsroom\n",
      "Apple Leadership\n",
      "Career Opportunities\n",
      "Investors\n",
      "Ethics & Compliance\n",
      "Events\n",
      "Contact Apple\t\t\tMore ways to shop: Find an Apple Store or other retailer near you. Or call 1-800-MY-APPLE.United StatesCopyright ©\n",
      "\t\t\t\t\n",
      "\t\t\t\t2025\n",
      "\t\t\t\t Apple Inc. All rights reserved.\n",
      "\t\t\tPrivacy PolicyTerms of UseSales and RefundsLegalSite MapDocument 2:::\n",
      "A subscription is required for Apple Arcade, Apple Fitness+, Apple Music, and Apple TV+.Features are subject to change. Some features, applications, and services may not be available in all regions or all languages.Shop and LearnShop and LearnStore\n",
      "Mac\n",
      "iPad\n",
      "iPhone\n",
      "Watch\n",
      "Vision\n",
      "AirPods\n",
      "TV & Home\n",
      "AirTag\n",
      "Accessories\n",
      "Gift CardsApple WalletApple WalletWallet\n",
      "Apple Card\n",
      "Apple Pay\n",
      "Apple CashAccountAccountManage Your Apple Account\n",
      "Apple Store Account\n",
      "iCloud.comEntertainmentEntertainmentApple One\n",
      "Apple TV+\n",
      "Apple Music\n",
      "Apple Arcade\n",
      "Apple Fitness+\n",
      "Apple News+\n",
      "Apple Podcasts\n",
      "Apple Books\n",
      "App StoreApple StoreApple StoreFind a Store\n",
      "Genius Bar\n",
      "Today at Apple\n",
      "Group Reservations\n",
      "Apple Camp\n",
      "Apple Store App\n",
      "Certified Refurbished\n",
      "Apple Trade In\n",
      "Financing\n",
      "Carrier Deals at Apple\n",
      "Order Status\n",
      "Shopping HelpFor BusinessFor BusinessApple and Business\n",
      "Shop for BusinessFor EducationFor Education\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: What new products are announced on Apple.com?</s>\n",
      "<|assistant|>\n",
      "Questions About Current Market Reports:\n",
      "Question: What technology is being used with products manufactured by Apple?\n",
      "<|business|>\n",
      "Questions About New Software and Services:\n",
      "Question: What is a new Apple product?\n",
      "<|device|>\n",
      "Questions About New Software & Services:\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
